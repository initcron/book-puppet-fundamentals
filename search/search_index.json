{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to Puppet Bootcamp by School of Devops\n\n\nThis is a Lab Guide which goes along with the Zero to Puppet Course by School of Devops. \n\n\nFor information about the devops trainign courses visit \nschoolofdevops.com\n.\n\n\nTeam\n\n\n\n\nGourav Shah", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-puppet-bootcamp-by-school-of-devops", 
            "text": "This is a Lab Guide which goes along with the Zero to Puppet Course by School of Devops.   For information about the devops trainign courses visit  schoolofdevops.com .", 
            "title": "Welcome to Puppet Bootcamp by School of Devops"
        }, 
        {
            "location": "/#team", 
            "text": "Gourav Shah", 
            "title": "Team"
        }, 
        {
            "location": "/Chapter01/", 
            "text": "How I got started with Puppet and Devops ?\n\n\nAs Georg Buchner said:\n\n\n\n\nWe are only puppets, our strings\nare being pulled by unknown forces.\n\n\n\n\nMy journey with Puppet began back in 2008, when as I was part of the Ops Team managing web scale infrastructure for a SaaS company. Our team consisted of ops engineers in  India and US working out of  their respective timezones, keeping lights on 24x7.  As part of day to day operations, all of us would  make ad hoc changes to the servers, and not always communicate back with the team on the other side of the globe. We did not have daily sync up meetings either. As a result of this ad hoc, inconsistent setup, regularly, issues would pop up with the product, in pre production/integration as well as in production environments. Being in charge of triaging, my team would  spend a lot of time flipping through logs, doing root cause analysis and  figuring out whether its a problem due to inconsistent configurations or a actual code related issue. Tired of this fire fighting, we started looking for solutions to help us efficiently manage this environment. And thats when we came across Puppet, which was popular, was already picked by likes of google, and had an active community around it. We started using it to setup the infrastructure as well as manage changes through a centralized console.\n\n\nResults were immediate, and tangible. After implementing puppet based configuration management system,\n\n\n\n\n\n\nWe now had a centralized tool which streamlined our process of managing configurations. This resulted in minimal ad hoc changes and \nconsistency\n across the environments.\n\n\n\n\n\n\nVisibility\n was another important outcome. Since we started writing infrastructure as a Code, everyone including the developers had \nvisibility\n into the way infrastructure was configured. All one had to do was look at the svn/git repository, the last commits to know what changes were made, my whom and when. What more, developers could even tweak the application properties in their own integration environments.\n\n\n\n\n\n\nError rates\n, specially related to configurations dropped  significantly, giving us more time back in our day, to focus on scale and other important issues.\n\n\n\n\n\n\nThat was the beginning of my journey with devops automation tools, which also includes exposure to Chef, and Ansible. Puppet was the first kid on the block, and has come a long way from the time it was created by \nLuke Kanies\n along with initial developers in 2005, to become a very matured and a indispensable tool in the kitty of a devops engineer.\n\n\nBefore we start looking into what makes puppet a excellent choice for a automation tool, lets first understand what configuration management is about.\n\n\nInfrastructure Life Events and Puppet\n\n\nIf you are the one  who is in the business of managing  more than a handful of systems, you should be familiar with the term \"Configuration Management\" (not to confuse with traditional Software Configuration Management or SCM). Be it physical servers, virtual machines or cloud based setup, infrastructure typically goes through the  following life events,\n\n\n\n\n\n\nProvisioning\n\n\nProvision servers - physical, virtual or cloud. This is where the servers are brought into being.\n\n\n\n\nInstall Operating System either using manual/automated install process or using an image/template.\n\n\n\n\n\n\nConfiguration Management\n\n\n\n\nBase Systems Configurations:  Prepare the systems with the base configurations such as users,  packages, security configurations, network setup etc.\n\n\nTech Stack: install and configure services such as apache, tomcat, middle wares, setup cron jobs, install and configure databases etc.\n\n\n\n\nApplication: Deploy the application code on top of the tech stack configured. This is where the code written by your team gets deployed with relevant configurations.\n\n\n\n\n\n\nChange Management\n\n  Configurations made during the initial setup do not remain  do not last for a life time. Infrastructure is in the constant state of flux  and evolves over time. Change management involves,\n\n\n\n\nUpdating configurations parameters across a class of servers eg. update port that web server is running on.\n\n\nDeploying new versions of the application code, push security patches etc, install additional services.\n\n\n\n\nPuppet serves as a excellent tool for Configuration Management as well as Change Management. And along with tools such as Razor, Cloud Plugins, Vagrant, Terraform it could also  automate provisioning of servers too. However puppet as a tool by itself does have an ability to provision and comes in to play once the Operating System is installed and puppet agent is setup.\n\n\nIf you are looking for a tool which could also provision servers, and do it effectively, you should  consider Ansible.\n\n\nEvolution of Configuration Management\n\n\nThe need for managing configurations and ongoing  changes had been a challenge which has seen various approaches. Lets have a look at the evolution of configuration management,\n\n\nManual\n\n\nAs systems engineers, we almost always begin configuring systems by hand, in a ad hoc manner. This approach is the easiest, and useful when you have only a handful of systems to manage, simple configurations, and where you do not have repeatable tasks or updates. However, as you start growing, this crude approach quickly gets out of control. It also involves manual processes, which mandates a operator to be present, and is prone to errors or omissions.\n\n\nScripts\n\n\nScripts allow one to take a sequence of commands to run and put it in a procedural program. Whenever there is need to repeat the process,  scripts come in very handy. Some of the popular scripting languages amongst the systems personnel include shell/bash, perl, python, ruby or powershell.  Scripts are almost always the first approach towards automating manual tasks. However, scripts are not scalable or flexible enough to manage a sophisticated infrastructure spanning across multitude of environments or the ones involving multiple different operating systems etc.\n\n\nConfiguration Management and  Software Configuration Management\n\n\nSoftware Configuration Management is referred to often with context of\nRevision Control which is about tracking changes to the application code.\nThis is just one part of a larger field of Configuration Management.  \n\n\nGolden Images/ Templates\n\n\nGolden images, or templates, or simply os images, are probably the quickest way to deploy servers complete with configurations, specially in virtual or cloud environments. Images are nothing but pre baked templates with operations system files, applications, and configurations. Take any cloud provider, and one of the first components to choose while you provision a server is the images. A lot of organizations these days package their products in the form of images such as ova, vmdk or even vagrant's box format. However images have one major problem i.e. change management. Every time there is an update, even a single line change,  one needs to build a new image. Not only this complete system image needs to be distributed but also existing systems need to be replaced with the new image. Imagine doing that in a dynamic environment involving frequent updates across  hundreds of servers. That could get too cumbersome. And thats where the need to come up with a new approach.  \n\n\nInfrastructure as a Code\n\n\n\"Infrastructure as a Code\" or \"Programmable Infrastructure\" is where today's generation tools such as Puppet, Chef, Ansible, Salt fit in. These tools essentially allow one to write the state of the infrastructure using a higher level descriptive  language and store it as a code. Since this is a code, one could bring in the best practices that developers have been following for years e.g. using revision control systems, use of sophisticated editors, test driven development, peer programming etc. You could  even build the complete infrastructure from scratch in case of a disaster, as long as you have the code repository, compute resources and data backups in place. Since this code is written in a simple declarative syntax, it is self documenting and offers visibility to all stakeholders into the way infrastructure is built and configured.\n\n\n\n\n\n\n\n\n\n\nApproach\n\n\nAdvantages\n\n\nDisadvantages\n\n\n\n\n\n\n\n\n\n\nManual\n\n\nsimple\n\n\nad hoc, error prone, inconsistent, not repeatable\n\n\n\n\n\n\nScripts\n\n\nrepeatable, automated\n\n\nprocedural, not scalable, inflexible\n\n\n\n\n\n\nImages\n\n\nrepeatable, automated\n\n\nsize, change management is not easy\n\n\n\n\n\n\nInfrastructure as a Code\n\n\nrepeatable, flexible, scalable, automated, consistent\n\n\nagent based, learning curve\n\n\n\n\n\n\n\n\nWhy to use Puppet ?\n\n\nNow that we have started discussion on   Infrastructure as a Code, specifically Puppet, lets discuss about the specific features of puppet that make it a useful tool for configuration and change management.\n\n\nDeclarative vs Procedural Approach\n\n\nScripts take a procedural approach towards automation. With scripts, we focus on the \nhow\n part. e.g. how to install a package, how to create a user, how to modify it later, how to do it on a specific platform. And if you would want to add a support for another platform, you may have to add additional procedure and write a conditional to check for the platform and call the relevant code. This involves a lot of efforts.\n\n\nOn the other hand, Puppet takes a declarative approach towards automation. With Puppet, our focus changes from   \nhow\n part to \nwhat\n. Instead of writing procedures, we start using a simple declarative syntax to define the desired state of infrastructure.  Let me explain this with an analogy.\n\n\nLets say we want to build a house. When we  set out to do so, we hire a contractor, who in turns has a team of construction workers who know how to build it brick by brick. They do all the hard work to bring our house into a reality. Thats the \nhow\n part.\n\n\nOn the other hand, you have a Architect. Lets take a moment and think about what he or she does. An Architect creates a plan, a blue print, which is nothing but a description of how your house should look like. The architect envisions the end state of your house, thinks about \nwhat\n should it consists of, breaks it down into components,  and starts creating  specification for each. He would then stitch it together to create a blueprint of our house, and hands it to the contractor to go and build it. This is the how part.\n\n\nThats exactly what we would start doing with puppet, only difference being, we write the specification for desired state of IT infrastructure.\n\n\nResource Abstraction Layer\n\n\nWe just learnt about puppet allowing us to write the desired state of the infrastructure using a descriptive language. Now  this concept is brought into a reality with the its Domain Specific Language(DSL) which consists of a Resource Abstraction Layer (RAL). Lets describe how this works,\n\n\nTODO\n: Create an image for each step below.\n\n\n\n\nPuppet looks at  infrastructure as a collection of entities to manage e.g. package, service, user, network interface etc.\n\n\nIt then takes the  procedures, the actual logic to manage these entities and  bundles it into something called as \nProviders\n. Providers are platform specific. That way, each entity may have multiple providers e.g. managing user on linux vs osx vs windows.\n\n\nOn top of these procedures, puppet creates an abstraction layer. Instead of defining the procedures, it offers the users a simple declarative syntax to define the state of the entity and its properties, in the form of \nResources\n.\n\n\nPuppet, then does the translation between Resources and Providers, and calls the procedure to put the entity in to the desired state just as described by the user.\n\n\n\n\nThis behavior allows the users of the puppet to create policies stating what which entities should be present or absent, with what properties.\n\n\nConvergence and Idempotence\n\n\nPuppet reads the resources, calls the relevant providers for the platform it runs on, and ensures the desired state of the resource is achieved. While it does so, it may need to make changes to the system. But what if the resource has already achieved the desired state and needs no further updates?  Puppet has the  built in intelligence to know what is the current state of the resource is. Instead of making changes blindly, it first compares the current state of the resource with the desired state, and the makes a decision whether it requires any changes, and if yes, what changes to make.  This process is called as convergence.\n\n\nTODO\n: Draw diagrams, maybe just a flowchart\n\n\ne.g.\n\n\nLets assume we have written a resource to create  a user  with a password.\n\n\nuser{'xyz':\n  uid       =\n  '501',\n  gid       =\n  '501',\n  home      =\n  '/home/xyz',\n  password  =\n  '$1$foYKL0zO$elXbUOb/JjHqS4aI8O25i.'\n}\n\n\n\n\n\n\n\n\nFirst time puppet applies this resource on the system, the user may not exist. Puppet detects the current state, compares it with the desired state which mentions it should exist, and finds the configuration drift. It then creates the user with the password to bring the current state to desired state.\n\n\n\n\n\n\nLets assume we run puppet again to apply the same resource. This time too it will compare the desired state with current state. Since the user is already present with the password provided, it deems no changes necessary. Instead of attempting to create the user again, it will skip the resource and move on to the next one.\n\n\n\n\n\n\nLets assume we updated the password information for the user in our code description of the resource, and excute puppet. This time, while comparing the current state with desired state, it detects that the user is present, but the password is updated. It does not attempt to create a user, but only changes one property i.e. password.\n\n\n\n\n\n\nIdempotence is a useful property to  ensures that puppet maintains the state of the infrastructure such that its always  in the policy. This also makes change management easier as one could keep running puppet as a service which invokes itself at regular intervals, pulls the changes, and apply only what is changed.\n\n\nCentralized Configuration Management System\n\n\nA typical installation of puppet involves  a Puppet Master, which is a centralized management console and Agents runnings on every node managed.  Any changes to nodes have to go through the Puppet Master. This streamlines the process of pushing updated.  Instead of iterating over a list of hosts using a for loop or other such methods, or logging into each system to make changes, all you need to do is push updates to Puppet Master, from where those are automatically propogated to the nodes.\n\n\nTODO\n \n\n\nPull Approach\n\n\nWhile puppet offers a centralized management approach, it works unlike most client server schemes. Instead of pushing updates to the nodes from master, its the duty of puppet agent to go the master,  pull changes, and apply. Pull method offers more flexibility and scalability for the following reasons,\n\n\n\n\n\n\nEach node could decide how frequently or infrequently it should update. Some systems need frequent updates, where as others need not be updated for weeks. This could be controlled at  per client level.\n\n\n\n\n\n\nNo need to manage inventory and connection details on the master. Nodes could come and go, and could be configured based on dynamic rules to classify them based on certain property e.g. host names, environments, or even hardware addresses.\n\n\n\n\n\n\nWith push based approach, master must have a ability reach out and connect to each node managed in order to configure it. A lot of times you may have a master on a cloud or in a separate data center than nodes being managed, which could be behind a firewall or NAT device in a private network. In case of pull method, as long as the master is available on a well known address, and is reachable from the nodes, configurations can be pulled and applied.\n\n\n\n\n\n\nCode vs Data\n\n\nA lot of applications that we configure on our servers are generic eg. apache, tomcat, mysql, mongo. These applications have a install base of hundreds of thousands of servers, used by organizations across the globe. Ever wondered how these become specific to your environment ? Even though you use the same apache web server used by many others, its how you configure it makes the difference. Even in single organization, you may have a apache server which behaves differently in different environment based on the configuration profile created. The process of setting up an application involves,\n\n\n\n\nInstalling the generic application either from a source, package or a repository.\n\n\nAdding data. This where you set configuration parameters  e.g. port, user, max connections, webroot for apache.\n\n\nStart, enable the service.\n\n\n\n\nPuppet allows separation of  code and data.\n\n\n\n\nUsing Puppet's DSL, we write infrastructure code to install packages start services etc. Code is generic.\n\n\nPuppet's variables/parameters/facts, scopes, templates, along with tools such as Hiera and ENC provide a way to create different configuration profiles specific to different nodes, environments, platforms etc.\n\n\n\n\nShared Library of Infrastructure Code\n\n\nWith puppet's ability to separate code and configuration data, the declarative code that you write in the form of modules with  puppet becomes generic enough to be shared and be reused. And since this code is in the version control, hosted services such as github offer the perfect means to publish this code. As you start writing code with puppet, you would discover about puppet forge, a library of community written modules. At the time of writing, there are more than 4000 modules available on puppet forge. Similar to a lot of open source code, you need not re invent the wheel. For most open source applications, you would find very sophisticated modules which you could use without even single line change. Download the modules, install it on your own puppet master, add configuration profile, and off you go.\n\n\nCloud Integrations\n\n\nWith emergence of cloud, computing is moving towards the utility model. More and more organizations have already migrated or contemplating to migrate a partial or whole of their computing setup to cloud. And with that happening, which ever automation tool that you would consider, needs to have a close integration with the cloud platform that you plan to use. Provisioning of infrastructure components before puppet comes in and starts configuring  There are two ways Puppet provides a way for this,\n\n\n\n\n\n\nThrough library of custom resources/libraries  which allow one to write provisioning of cloud components in the form of resources.\n\n\n\n\n\n\nCloud specific tools e.g. Cloudformation on AWS or Heat on Openstack are some of the tools which help provision components which are specific to that cloud and then call puppet to do the configurations.\n\n\n\n\n\n\nThird party tools such as Vagrant, Terraform have in turn ability to talk to multiple cloud providers. These tools typically provision servers on the cloud and then hand it off to puppet for configurations.\n\n\n\n\n\n\nIterative Approach to Automation\n\n\nHowever convinced you are with Puppet, scrapping  your existing automation tool  overnight for a shiny new tool may have  unknown risks attached. More over, it may could  be challenging  to get a buy in from your management to invest in time, money and resources to implement a new solution without showing them the value.\n\n\nWith puppet, you could take a iterative approach towards automation. You could start with a single application, or even a single entity such as a system user to manage. Once you see the value, show it to all stake holders, get a buy in and move to the next application, one at a time.\n\n\nDevice Support\n\n\nManaging configurations on systems running common operating systems such as windows, linux, os x, where puppet agent application  can be installed is easy.  Its a completely different beast when it comes to   managing configurations on  devices running their own specialized version of operating systems/firmwares. Examples are configuring CISCO's network switches routers, EMC's storage array.\n\n\nAlong with programmable infrastructures, new concepts such as Software Defined Networking(SDN) and Software Defined Storage(SDS) are taking root and changing the way devices are being managed. Puppet supports managing devices in two ways,\n\n\n\n\nDevices that are based on linux and have puppet agent ported to run on those can be configured the same way as other generic systems.\n\n\nSub set of devices that do not have puppet agent can still be configured with puppet's device support over ssh/telnet. For such devices, puppet uses push instead of pull approach.\n\n\n\n\nAudit and Compliance\n\n\nWith ability to define the state of the  infrastructure components as a code and then  converge, one could easily codify the infrastructure policies and have them enforced. Puppets ability to test, log changes, and reporting mechanisms  help keeping a trail of the state of the systems and its components over time and track who made changes, when, if there are any nodes which have fallen out of policy etc.\n\n\nWhen to Use Puppet ?\n\n\nYou should consider using puppet for the following purposes,\n\n\n\n\nConfiguration Management\n + Change Management: You have many nodes to deploy with changes happening often. You need to update the nodes and applications running on those often.\n\n\nCompliance and Audit\n: When your organization has to comply to policies and you need an ability to convert those policies into a code which would auto correct and bring the nodes into the policy in case of configuration drifts. You also need to audit the systems regularly and prepare reports to find out which nodes have drifted away from the policy etc. as well as mitigate such issues.\n\n\nSoftware Delivery\n : If you are in business of building software and delivering as ova images or similar, puppet is better approach to deliver the product and push updates to it.\n\n\n\n\nWho is it for?\n\n\n\n\nSystems Administrators/Engineers who are managing systems at scale and  need to install, configure, patch, monitor and maintain systems and prepared reports for.\n\n\nApplication Operations Engineers  who are responsible for installing, configuring, integrating, monitoring, maintaining application infrastructures.\n\n\nBuild and release engineers who are in charge of setting up environments for CI/CD cycles, as well as deploy/release applications to production environments.\n\n\nNetwork Engineers who configure and maintain networking devices such as CISCO Routers and Switches at scale.\n\n\nStorage Administrators who configure and maintain storage devices.\n\n\nDevelopers who are building application delivery to their customers. Also as users of the develops tools, developers may need to change application properties for  the environments that they create/use.  \n\n\n\n\nWhat Puppet is not?\n\n\n\n\n\n\nGraphical Management Tool (e.g. SCCM):\n  If you are looking for a tool which would allow you to manage everything through a graphical interface without writing any code or without ever having to use an editor, well puppet is not the tool for you.  I have come across many engineers, who say \"well, the capabilities of puppet sounds great, but can I do all of this using a GUI where I can just click click and get things done.... ? \" Well, its infrastructure as a code is what we are talking about. Even though enterprise puppet puppet offers a nice GUI, its mostly for reporting and classifications. Since I started using puppet and similar tools, I have been using text editors more often.\n\n\n\n\n\n\nAutomated Testing Tool ( e.g. selenium ):\n  Its not a silver bullet. Its not one solutions to all. I meet a lot of QA folks who have heard that puppet would automate everything and you could use it for testing too.  Well, there is always a special purpose tool for each task and the application testing is not puppet's ball game.  Sure puppet could help in testing by letting you automate the process of building and configuring a fresh environment to run your tests inside, and give you ability to do it repeatedly. It also gives you a way to test infrastrcuture code. However, its not a test automation tool.\n\n\n\n\n\n\nPure Application Deployment and Orchestration Tool:\n  Even though Puppet has been talking about application orchestration, if you are looking for a tool purely for application deployments, rolling updates, canary releases, orchestrated deployments over multiple hosts, you have tools which do it better. A few  tools I could suggest you for application deployment and orchestration are Asible, Capistrano, Code Deploy  which are push based, and work better in such scenarios.\n\n\n\n\n\n\nAgent less Management System:\n  Except for a sub set of network devices, puppet mandates running agents on each node being managed. In fact its designed to be heavy on the agent side which is responsible to initiate communication with the master, pull policies,  enforce and report back.  If you need a agent less management system, puppet is not the one. Again, I would suggest using Ansible in such cases, which works over ssh and is agent less.\n\n\n\n\n\n\nSoftware Configuration Management(SCM) Tool\n  SCM is a part of the larger Configuration Management and typically refers to the practice of revision/version control. Puppet is not the tool which does the version control, however it can be used to replicate and manage software configurations across a cluster of nodes.\n\n\n\n\n\n\nA one stop  Devops solutions\n\n\n\n\n\n\nPuppet Use Cases/ Customer Stories\n\n\n\n\n\n\nPuppet vs Chef\n\n\nPuppet vs Ansible\n\n\nPuppet vs Docker\n\n\nUpgrading from Puppet 3 to Puppet 4\n\n\nUsing Tidy to clean up unwanted files", 
            "title": "Intro"
        }, 
        {
            "location": "/Chapter01/#how-i-got-started-with-puppet-and-devops", 
            "text": "As Georg Buchner said:   We are only puppets, our strings\nare being pulled by unknown forces.   My journey with Puppet began back in 2008, when as I was part of the Ops Team managing web scale infrastructure for a SaaS company. Our team consisted of ops engineers in  India and US working out of  their respective timezones, keeping lights on 24x7.  As part of day to day operations, all of us would  make ad hoc changes to the servers, and not always communicate back with the team on the other side of the globe. We did not have daily sync up meetings either. As a result of this ad hoc, inconsistent setup, regularly, issues would pop up with the product, in pre production/integration as well as in production environments. Being in charge of triaging, my team would  spend a lot of time flipping through logs, doing root cause analysis and  figuring out whether its a problem due to inconsistent configurations or a actual code related issue. Tired of this fire fighting, we started looking for solutions to help us efficiently manage this environment. And thats when we came across Puppet, which was popular, was already picked by likes of google, and had an active community around it. We started using it to setup the infrastructure as well as manage changes through a centralized console.  Results were immediate, and tangible. After implementing puppet based configuration management system,    We now had a centralized tool which streamlined our process of managing configurations. This resulted in minimal ad hoc changes and  consistency  across the environments.    Visibility  was another important outcome. Since we started writing infrastructure as a Code, everyone including the developers had  visibility  into the way infrastructure was configured. All one had to do was look at the svn/git repository, the last commits to know what changes were made, my whom and when. What more, developers could even tweak the application properties in their own integration environments.    Error rates , specially related to configurations dropped  significantly, giving us more time back in our day, to focus on scale and other important issues.    That was the beginning of my journey with devops automation tools, which also includes exposure to Chef, and Ansible. Puppet was the first kid on the block, and has come a long way from the time it was created by  Luke Kanies  along with initial developers in 2005, to become a very matured and a indispensable tool in the kitty of a devops engineer.  Before we start looking into what makes puppet a excellent choice for a automation tool, lets first understand what configuration management is about.", 
            "title": "How I got started with Puppet and Devops ?"
        }, 
        {
            "location": "/Chapter01/#infrastructure-life-events-and-puppet", 
            "text": "If you are the one  who is in the business of managing  more than a handful of systems, you should be familiar with the term \"Configuration Management\" (not to confuse with traditional Software Configuration Management or SCM). Be it physical servers, virtual machines or cloud based setup, infrastructure typically goes through the  following life events,    Provisioning  Provision servers - physical, virtual or cloud. This is where the servers are brought into being.   Install Operating System either using manual/automated install process or using an image/template.    Configuration Management   Base Systems Configurations:  Prepare the systems with the base configurations such as users,  packages, security configurations, network setup etc.  Tech Stack: install and configure services such as apache, tomcat, middle wares, setup cron jobs, install and configure databases etc.   Application: Deploy the application code on top of the tech stack configured. This is where the code written by your team gets deployed with relevant configurations.    Change Management \n  Configurations made during the initial setup do not remain  do not last for a life time. Infrastructure is in the constant state of flux  and evolves over time. Change management involves,   Updating configurations parameters across a class of servers eg. update port that web server is running on.  Deploying new versions of the application code, push security patches etc, install additional services.   Puppet serves as a excellent tool for Configuration Management as well as Change Management. And along with tools such as Razor, Cloud Plugins, Vagrant, Terraform it could also  automate provisioning of servers too. However puppet as a tool by itself does have an ability to provision and comes in to play once the Operating System is installed and puppet agent is setup.  If you are looking for a tool which could also provision servers, and do it effectively, you should  consider Ansible.", 
            "title": "Infrastructure Life Events and Puppet"
        }, 
        {
            "location": "/Chapter01/#evolution-of-configuration-management", 
            "text": "The need for managing configurations and ongoing  changes had been a challenge which has seen various approaches. Lets have a look at the evolution of configuration management,", 
            "title": "Evolution of Configuration Management"
        }, 
        {
            "location": "/Chapter01/#manual", 
            "text": "As systems engineers, we almost always begin configuring systems by hand, in a ad hoc manner. This approach is the easiest, and useful when you have only a handful of systems to manage, simple configurations, and where you do not have repeatable tasks or updates. However, as you start growing, this crude approach quickly gets out of control. It also involves manual processes, which mandates a operator to be present, and is prone to errors or omissions.", 
            "title": "Manual"
        }, 
        {
            "location": "/Chapter01/#scripts", 
            "text": "Scripts allow one to take a sequence of commands to run and put it in a procedural program. Whenever there is need to repeat the process,  scripts come in very handy. Some of the popular scripting languages amongst the systems personnel include shell/bash, perl, python, ruby or powershell.  Scripts are almost always the first approach towards automating manual tasks. However, scripts are not scalable or flexible enough to manage a sophisticated infrastructure spanning across multitude of environments or the ones involving multiple different operating systems etc.", 
            "title": "Scripts"
        }, 
        {
            "location": "/Chapter01/#configuration-management-and-software-configuration-management", 
            "text": "Software Configuration Management is referred to often with context of\nRevision Control which is about tracking changes to the application code.\nThis is just one part of a larger field of Configuration Management.", 
            "title": "Configuration Management and  Software Configuration Management"
        }, 
        {
            "location": "/Chapter01/#golden-images-templates", 
            "text": "Golden images, or templates, or simply os images, are probably the quickest way to deploy servers complete with configurations, specially in virtual or cloud environments. Images are nothing but pre baked templates with operations system files, applications, and configurations. Take any cloud provider, and one of the first components to choose while you provision a server is the images. A lot of organizations these days package their products in the form of images such as ova, vmdk or even vagrant's box format. However images have one major problem i.e. change management. Every time there is an update, even a single line change,  one needs to build a new image. Not only this complete system image needs to be distributed but also existing systems need to be replaced with the new image. Imagine doing that in a dynamic environment involving frequent updates across  hundreds of servers. That could get too cumbersome. And thats where the need to come up with a new approach.", 
            "title": "Golden Images/ Templates"
        }, 
        {
            "location": "/Chapter01/#infrastructure-as-a-code", 
            "text": "\"Infrastructure as a Code\" or \"Programmable Infrastructure\" is where today's generation tools such as Puppet, Chef, Ansible, Salt fit in. These tools essentially allow one to write the state of the infrastructure using a higher level descriptive  language and store it as a code. Since this is a code, one could bring in the best practices that developers have been following for years e.g. using revision control systems, use of sophisticated editors, test driven development, peer programming etc. You could  even build the complete infrastructure from scratch in case of a disaster, as long as you have the code repository, compute resources and data backups in place. Since this code is written in a simple declarative syntax, it is self documenting and offers visibility to all stakeholders into the way infrastructure is built and configured.      Approach  Advantages  Disadvantages      Manual  simple  ad hoc, error prone, inconsistent, not repeatable    Scripts  repeatable, automated  procedural, not scalable, inflexible    Images  repeatable, automated  size, change management is not easy    Infrastructure as a Code  repeatable, flexible, scalable, automated, consistent  agent based, learning curve", 
            "title": "Infrastructure as a Code"
        }, 
        {
            "location": "/Chapter01/#why-to-use-puppet", 
            "text": "Now that we have started discussion on   Infrastructure as a Code, specifically Puppet, lets discuss about the specific features of puppet that make it a useful tool for configuration and change management.", 
            "title": "Why to use Puppet ?"
        }, 
        {
            "location": "/Chapter01/#declarative-vs-procedural-approach", 
            "text": "Scripts take a procedural approach towards automation. With scripts, we focus on the  how  part. e.g. how to install a package, how to create a user, how to modify it later, how to do it on a specific platform. And if you would want to add a support for another platform, you may have to add additional procedure and write a conditional to check for the platform and call the relevant code. This involves a lot of efforts.  On the other hand, Puppet takes a declarative approach towards automation. With Puppet, our focus changes from    how  part to  what . Instead of writing procedures, we start using a simple declarative syntax to define the desired state of infrastructure.  Let me explain this with an analogy.  Lets say we want to build a house. When we  set out to do so, we hire a contractor, who in turns has a team of construction workers who know how to build it brick by brick. They do all the hard work to bring our house into a reality. Thats the  how  part.  On the other hand, you have a Architect. Lets take a moment and think about what he or she does. An Architect creates a plan, a blue print, which is nothing but a description of how your house should look like. The architect envisions the end state of your house, thinks about  what  should it consists of, breaks it down into components,  and starts creating  specification for each. He would then stitch it together to create a blueprint of our house, and hands it to the contractor to go and build it. This is the how part.  Thats exactly what we would start doing with puppet, only difference being, we write the specification for desired state of IT infrastructure.", 
            "title": "Declarative vs Procedural Approach"
        }, 
        {
            "location": "/Chapter01/#resource-abstraction-layer", 
            "text": "We just learnt about puppet allowing us to write the desired state of the infrastructure using a descriptive language. Now  this concept is brought into a reality with the its Domain Specific Language(DSL) which consists of a Resource Abstraction Layer (RAL). Lets describe how this works,  TODO : Create an image for each step below.   Puppet looks at  infrastructure as a collection of entities to manage e.g. package, service, user, network interface etc.  It then takes the  procedures, the actual logic to manage these entities and  bundles it into something called as  Providers . Providers are platform specific. That way, each entity may have multiple providers e.g. managing user on linux vs osx vs windows.  On top of these procedures, puppet creates an abstraction layer. Instead of defining the procedures, it offers the users a simple declarative syntax to define the state of the entity and its properties, in the form of  Resources .  Puppet, then does the translation between Resources and Providers, and calls the procedure to put the entity in to the desired state just as described by the user.   This behavior allows the users of the puppet to create policies stating what which entities should be present or absent, with what properties.", 
            "title": "Resource Abstraction Layer"
        }, 
        {
            "location": "/Chapter01/#convergence-and-idempotence", 
            "text": "Puppet reads the resources, calls the relevant providers for the platform it runs on, and ensures the desired state of the resource is achieved. While it does so, it may need to make changes to the system. But what if the resource has already achieved the desired state and needs no further updates?  Puppet has the  built in intelligence to know what is the current state of the resource is. Instead of making changes blindly, it first compares the current state of the resource with the desired state, and the makes a decision whether it requires any changes, and if yes, what changes to make.  This process is called as convergence.  TODO : Draw diagrams, maybe just a flowchart  e.g.  Lets assume we have written a resource to create  a user  with a password.  user{'xyz':\n  uid       =   '501',\n  gid       =   '501',\n  home      =   '/home/xyz',\n  password  =   '$1$foYKL0zO$elXbUOb/JjHqS4aI8O25i.'\n}    First time puppet applies this resource on the system, the user may not exist. Puppet detects the current state, compares it with the desired state which mentions it should exist, and finds the configuration drift. It then creates the user with the password to bring the current state to desired state.    Lets assume we run puppet again to apply the same resource. This time too it will compare the desired state with current state. Since the user is already present with the password provided, it deems no changes necessary. Instead of attempting to create the user again, it will skip the resource and move on to the next one.    Lets assume we updated the password information for the user in our code description of the resource, and excute puppet. This time, while comparing the current state with desired state, it detects that the user is present, but the password is updated. It does not attempt to create a user, but only changes one property i.e. password.    Idempotence is a useful property to  ensures that puppet maintains the state of the infrastructure such that its always  in the policy. This also makes change management easier as one could keep running puppet as a service which invokes itself at regular intervals, pulls the changes, and apply only what is changed.", 
            "title": "Convergence and Idempotence"
        }, 
        {
            "location": "/Chapter01/#centralized-configuration-management-system", 
            "text": "A typical installation of puppet involves  a Puppet Master, which is a centralized management console and Agents runnings on every node managed.  Any changes to nodes have to go through the Puppet Master. This streamlines the process of pushing updated.  Instead of iterating over a list of hosts using a for loop or other such methods, or logging into each system to make changes, all you need to do is push updates to Puppet Master, from where those are automatically propogated to the nodes.  TODO", 
            "title": "Centralized Configuration Management System"
        }, 
        {
            "location": "/Chapter01/#pull-approach", 
            "text": "While puppet offers a centralized management approach, it works unlike most client server schemes. Instead of pushing updates to the nodes from master, its the duty of puppet agent to go the master,  pull changes, and apply. Pull method offers more flexibility and scalability for the following reasons,    Each node could decide how frequently or infrequently it should update. Some systems need frequent updates, where as others need not be updated for weeks. This could be controlled at  per client level.    No need to manage inventory and connection details on the master. Nodes could come and go, and could be configured based on dynamic rules to classify them based on certain property e.g. host names, environments, or even hardware addresses.    With push based approach, master must have a ability reach out and connect to each node managed in order to configure it. A lot of times you may have a master on a cloud or in a separate data center than nodes being managed, which could be behind a firewall or NAT device in a private network. In case of pull method, as long as the master is available on a well known address, and is reachable from the nodes, configurations can be pulled and applied.", 
            "title": "Pull Approach"
        }, 
        {
            "location": "/Chapter01/#code-vs-data", 
            "text": "A lot of applications that we configure on our servers are generic eg. apache, tomcat, mysql, mongo. These applications have a install base of hundreds of thousands of servers, used by organizations across the globe. Ever wondered how these become specific to your environment ? Even though you use the same apache web server used by many others, its how you configure it makes the difference. Even in single organization, you may have a apache server which behaves differently in different environment based on the configuration profile created. The process of setting up an application involves,   Installing the generic application either from a source, package or a repository.  Adding data. This where you set configuration parameters  e.g. port, user, max connections, webroot for apache.  Start, enable the service.   Puppet allows separation of  code and data.   Using Puppet's DSL, we write infrastructure code to install packages start services etc. Code is generic.  Puppet's variables/parameters/facts, scopes, templates, along with tools such as Hiera and ENC provide a way to create different configuration profiles specific to different nodes, environments, platforms etc.", 
            "title": "Code vs Data"
        }, 
        {
            "location": "/Chapter01/#shared-library-of-infrastructure-code", 
            "text": "With puppet's ability to separate code and configuration data, the declarative code that you write in the form of modules with  puppet becomes generic enough to be shared and be reused. And since this code is in the version control, hosted services such as github offer the perfect means to publish this code. As you start writing code with puppet, you would discover about puppet forge, a library of community written modules. At the time of writing, there are more than 4000 modules available on puppet forge. Similar to a lot of open source code, you need not re invent the wheel. For most open source applications, you would find very sophisticated modules which you could use without even single line change. Download the modules, install it on your own puppet master, add configuration profile, and off you go.", 
            "title": "Shared Library of Infrastructure Code"
        }, 
        {
            "location": "/Chapter01/#cloud-integrations", 
            "text": "With emergence of cloud, computing is moving towards the utility model. More and more organizations have already migrated or contemplating to migrate a partial or whole of their computing setup to cloud. And with that happening, which ever automation tool that you would consider, needs to have a close integration with the cloud platform that you plan to use. Provisioning of infrastructure components before puppet comes in and starts configuring  There are two ways Puppet provides a way for this,    Through library of custom resources/libraries  which allow one to write provisioning of cloud components in the form of resources.    Cloud specific tools e.g. Cloudformation on AWS or Heat on Openstack are some of the tools which help provision components which are specific to that cloud and then call puppet to do the configurations.    Third party tools such as Vagrant, Terraform have in turn ability to talk to multiple cloud providers. These tools typically provision servers on the cloud and then hand it off to puppet for configurations.", 
            "title": "Cloud Integrations"
        }, 
        {
            "location": "/Chapter01/#iterative-approach-to-automation", 
            "text": "However convinced you are with Puppet, scrapping  your existing automation tool  overnight for a shiny new tool may have  unknown risks attached. More over, it may could  be challenging  to get a buy in from your management to invest in time, money and resources to implement a new solution without showing them the value.  With puppet, you could take a iterative approach towards automation. You could start with a single application, or even a single entity such as a system user to manage. Once you see the value, show it to all stake holders, get a buy in and move to the next application, one at a time.", 
            "title": "Iterative Approach to Automation"
        }, 
        {
            "location": "/Chapter01/#device-support", 
            "text": "Managing configurations on systems running common operating systems such as windows, linux, os x, where puppet agent application  can be installed is easy.  Its a completely different beast when it comes to   managing configurations on  devices running their own specialized version of operating systems/firmwares. Examples are configuring CISCO's network switches routers, EMC's storage array.  Along with programmable infrastructures, new concepts such as Software Defined Networking(SDN) and Software Defined Storage(SDS) are taking root and changing the way devices are being managed. Puppet supports managing devices in two ways,   Devices that are based on linux and have puppet agent ported to run on those can be configured the same way as other generic systems.  Sub set of devices that do not have puppet agent can still be configured with puppet's device support over ssh/telnet. For such devices, puppet uses push instead of pull approach.", 
            "title": "Device Support"
        }, 
        {
            "location": "/Chapter01/#audit-and-compliance", 
            "text": "With ability to define the state of the  infrastructure components as a code and then  converge, one could easily codify the infrastructure policies and have them enforced. Puppets ability to test, log changes, and reporting mechanisms  help keeping a trail of the state of the systems and its components over time and track who made changes, when, if there are any nodes which have fallen out of policy etc.", 
            "title": "Audit and Compliance"
        }, 
        {
            "location": "/Chapter01/#when-to-use-puppet", 
            "text": "You should consider using puppet for the following purposes,   Configuration Management  + Change Management: You have many nodes to deploy with changes happening often. You need to update the nodes and applications running on those often.  Compliance and Audit : When your organization has to comply to policies and you need an ability to convert those policies into a code which would auto correct and bring the nodes into the policy in case of configuration drifts. You also need to audit the systems regularly and prepare reports to find out which nodes have drifted away from the policy etc. as well as mitigate such issues.  Software Delivery  : If you are in business of building software and delivering as ova images or similar, puppet is better approach to deliver the product and push updates to it.", 
            "title": "When to Use Puppet ?"
        }, 
        {
            "location": "/Chapter01/#who-is-it-for", 
            "text": "Systems Administrators/Engineers who are managing systems at scale and  need to install, configure, patch, monitor and maintain systems and prepared reports for.  Application Operations Engineers  who are responsible for installing, configuring, integrating, monitoring, maintaining application infrastructures.  Build and release engineers who are in charge of setting up environments for CI/CD cycles, as well as deploy/release applications to production environments.  Network Engineers who configure and maintain networking devices such as CISCO Routers and Switches at scale.  Storage Administrators who configure and maintain storage devices.  Developers who are building application delivery to their customers. Also as users of the develops tools, developers may need to change application properties for  the environments that they create/use.", 
            "title": "Who is it for?"
        }, 
        {
            "location": "/Chapter01/#what-puppet-is-not", 
            "text": "Graphical Management Tool (e.g. SCCM):\n  If you are looking for a tool which would allow you to manage everything through a graphical interface without writing any code or without ever having to use an editor, well puppet is not the tool for you.  I have come across many engineers, who say \"well, the capabilities of puppet sounds great, but can I do all of this using a GUI where I can just click click and get things done.... ? \" Well, its infrastructure as a code is what we are talking about. Even though enterprise puppet puppet offers a nice GUI, its mostly for reporting and classifications. Since I started using puppet and similar tools, I have been using text editors more often.    Automated Testing Tool ( e.g. selenium ):\n  Its not a silver bullet. Its not one solutions to all. I meet a lot of QA folks who have heard that puppet would automate everything and you could use it for testing too.  Well, there is always a special purpose tool for each task and the application testing is not puppet's ball game.  Sure puppet could help in testing by letting you automate the process of building and configuring a fresh environment to run your tests inside, and give you ability to do it repeatedly. It also gives you a way to test infrastrcuture code. However, its not a test automation tool.    Pure Application Deployment and Orchestration Tool:\n  Even though Puppet has been talking about application orchestration, if you are looking for a tool purely for application deployments, rolling updates, canary releases, orchestrated deployments over multiple hosts, you have tools which do it better. A few  tools I could suggest you for application deployment and orchestration are Asible, Capistrano, Code Deploy  which are push based, and work better in such scenarios.    Agent less Management System:\n  Except for a sub set of network devices, puppet mandates running agents on each node being managed. In fact its designed to be heavy on the agent side which is responsible to initiate communication with the master, pull policies,  enforce and report back.  If you need a agent less management system, puppet is not the one. Again, I would suggest using Ansible in such cases, which works over ssh and is agent less.    Software Configuration Management(SCM) Tool\n  SCM is a part of the larger Configuration Management and typically refers to the practice of revision/version control. Puppet is not the tool which does the version control, however it can be used to replicate and manage software configurations across a cluster of nodes.    A one stop  Devops solutions    Puppet Use Cases/ Customer Stories", 
            "title": "What Puppet is not?"
        }, 
        {
            "location": "/Chapter01/#puppet-vs-chef", 
            "text": "", 
            "title": "Puppet vs Chef"
        }, 
        {
            "location": "/Chapter01/#puppet-vs-ansible", 
            "text": "", 
            "title": "Puppet vs Ansible"
        }, 
        {
            "location": "/Chapter01/#puppet-vs-docker", 
            "text": "", 
            "title": "Puppet vs Docker"
        }, 
        {
            "location": "/Chapter01/#upgrading-from-puppet-3-to-puppet-4", 
            "text": "", 
            "title": "Upgrading from Puppet 3 to Puppet 4"
        }, 
        {
            "location": "/Chapter01/#using-tidy-to-clean-up-unwanted-files", 
            "text": "", 
            "title": "Using Tidy to clean up unwanted files"
        }, 
        {
            "location": "/install/", 
            "text": "Installation\n\n\nWith Vagrant\n\n\n# Import Vagrant Tempalte\n# Open iterm/ git bash  and browse to the dir where the box file is copied. Run the following\n\n# From puppet directory\n$ vagrant box add puppet-template devops-training-centos-v2.box\n\n# Validate\n$ vagrant box list\n\npuppet-template          (virtualbox, 0)\n\n\n# To Bring up the VMs with Vagrant and Virtualbox\n# Open iterm or git bash from virtual/multi directory\n# Open 3 different windows and cd into virtual/multi dir in each\n# bring up the VMs as\n\ncd virtual/multi\n\n$ vagrant up master\n$ vagrant up web\n#$ vagrant up db\n\n# Open three different windows, one for master, one for web and one for db servers, and login\n$ vagrant ssh master\n$ vagrant ssh web\n#$ vagrant ssh db\n\n#On Puppet Master\n$ sudo su\n$ yum install puppetserver puppet-agent -y\n$ service puppetserver start\n\n# Validate\n$ service puppetserver status\n\n\n#On Puppet Agents : all nodes\n$ sudo su\n$ yum install puppet-agent\n$ service puppet status\n$ service puppet start\n\n# Validate\n$ service puppet status\n\n# On Master, check for certificate request\n# Outstanding\n$ puppet cert list\n# All\n$ puppet cert list -a\n\n# Sign\n$ puppet cert sign -a\n\n# On agents run puppet\npuppet agent -t", 
            "title": "Puppet Installation using Vagrant"
        }, 
        {
            "location": "/install/#installation", 
            "text": "", 
            "title": "Installation"
        }, 
        {
            "location": "/install/#with-vagrant", 
            "text": "# Import Vagrant Tempalte\n# Open iterm/ git bash  and browse to the dir where the box file is copied. Run the following\n\n# From puppet directory\n$ vagrant box add puppet-template devops-training-centos-v2.box\n\n# Validate\n$ vagrant box list\n\npuppet-template          (virtualbox, 0)\n\n\n# To Bring up the VMs with Vagrant and Virtualbox\n# Open iterm or git bash from virtual/multi directory\n# Open 3 different windows and cd into virtual/multi dir in each\n# bring up the VMs as\n\ncd virtual/multi\n\n$ vagrant up master\n$ vagrant up web\n#$ vagrant up db\n\n# Open three different windows, one for master, one for web and one for db servers, and login\n$ vagrant ssh master\n$ vagrant ssh web\n#$ vagrant ssh db\n\n#On Puppet Master\n$ sudo su\n$ yum install puppetserver puppet-agent -y\n$ service puppetserver start\n\n# Validate\n$ service puppetserver status\n\n\n#On Puppet Agents : all nodes\n$ sudo su\n$ yum install puppet-agent\n$ service puppet status\n$ service puppet start\n\n# Validate\n$ service puppet status\n\n# On Master, check for certificate request\n# Outstanding\n$ puppet cert list\n# All\n$ puppet cert list -a\n\n# Sign\n$ puppet cert sign -a\n\n# On agents run puppet\npuppet agent -t", 
            "title": "With Vagrant"
        }, 
        {
            "location": "/Chapter04/", 
            "text": "Modules\n\n\nUpdate code dir to use your current workspace\n\n\nOn puppet master\n\n\npuppet\ncp -r /etc/puppetlabs/code /workspace/code    \n\n\n\n\nUpdate config in the server's config  file \n/etc/puppetlabs/puppetserver/conf.d/puppetserver.conf\n and update \n\n\nmaster-code-dir: /etc/puppetlabs/code\n\n\n\n\nto \n\n\nmaster-code-dir: /workspace/code\n\n\n\n\n(assuming you are using /workspace as your working/developement directory on the puppet master to store the code at )\n\n\nRestart Puppet Server \n\n\nshell\nservice puppetserver restart  \n\n\n\n\nThis may take time. \n\n\nGenerating Modules\n\n\nChange into the directory for production env \n\n\nsh\ncd /workspace/code/environments/production/modules\n\n\n\n\nUsing puppet module command, generate the scaffolding for \njava\n and \ntomcat\n modules\n\n\nbash\n\npuppet module generate --skip-interview user-java\n\npuppet module generate --skip-interview  gshah-tomcat\n\n\n\n\nWriting classes\n\n\nfile: \nmodules/java/manifests/init.pp\n\n\nclass java {\n\n  package { [ 'epel-release', 'java-1.7.0-openjdk'] : \n    ensure =\n installed,\n  }\n\n}\n\n\n\n\nNode Definitions - Applying the code\n\n\nTo apply the default class from java module, create a node definition \n\n\ncreate file: \nenvironments/production/manifests/app.pp\n\n\nadd the node definition \n\n\nnode 'node1' {\n\n   include java\n\n}\n\n\n\n\nTo apply, login to \nnode1\n and run puppet agent \n\n\nssh devops@node1\n\nsudo su\n\npuppet agent -t \n\n\n\n\n\nWriting the class to install tomcat\n\n\nfile: \nmodules/tomcat/manifests/install.pp\n\n\nclass tomcat::install {\n\n    include java\n\n    package { [ 'tomcat', 'tomcat-webapps' ]:\n      ensure   =\n installed, \n      require  =\n Package['epel-release']\n    }\n\n}\n\n\n\n\n\n\nAdd \ntomcat::install\n to node definition for node1 which should now look like \n\n\nnode 'node1' {\n\n   include java\n   include tomcat::install\n\n}\n\n\n\n\nApply on node1 by running puppet agent \n\n\n[on node1, as root]\n\npuppet agent -t \n\n\n\n\n\nNano Project\n\n\nNow that you have learnt how to write a manifest and apply, and have gone through the class naming conventions, you have been tasked to create  the following classe with the specifications as give below, \n\n\n\n\n\n\nclass :  tomcat::service \n      resource : service \n      name : tomcat \n      ensure : running \n      enable : true \n\n\n\n\n\n\nservice resource should have a dependency on install class\n\n\n\n\n\n\napply it to node1 by updating the node definition.  Validate by visiting the IP address of the server and port 8081. \n\n\n\n\n\n\nNote : Tomcat may take up to 10mins to come up for the first time. This is discussed in details on this page https://wiki.apache.org/tomcat/HowTo/FasterStartUp at the Entropy Source section. We are going to apply that fix in the subsequenct sections. \n\n\nAlso bootstrap node2 ( configure it to talk to the master), create a node definition identical to node1, and apply. Validate that the tomcat service is started on port 8082. \n\n\nSimplify Run List\n\n\nfile: \nmodules/tomcat/manifests/init.pp\n\n\nclass tomcat {\n\n  include tomcat::install\n  include tomcat::service \n\n}\n\n\n\n\n\nAnd \nproduction/manifests/app.pp\n\n\n\nnode 'node1' {\n\n  include tomcat\n\n}\n\n\nnode 'node2' {\n\n   include tomcat\n\n}\n\n\n\n\n\nQuestion\n : Why are we not including java anymore? \n\n\nManaging Files\n\n\n\n\n\n\nCreate file \n\n\n\n\ncreate directory to hold files : modules/tomcat/files\n\n\ncreate a file modules/tomcat/files/tomcat.conf and add the content from https://gist.github.com/initcron/01f8554fba3305a1bceee9df5ff0aa24\n\n\n\n\n\n\n\n\nCreate a class tomcat::config to copy this file to destinition \n\n\n\n\n\n\ntomcat::config class \n\n\nclass tomcat::config {\n\n  file { '/etc/tomcat/tomcat.conf':\n    source    =\n 'puppet:///modules/tomcat/tomcat.conf',\n    owner    =\n 'tomcat', \n    group    =\n 'tomcat', \n    mode     =\n '0644',\n    notify   =\n Service['tomcat'] \n  }\n\n}\n\n\n\n\n\nCall it from tomcat class (init.pp)\n\n\nclass tomcat {\n\n  include tomcat::install\n  include tomcat::config\n  include tomcat::service \n}\n\n\n\n\nApply on Node1 and Node2", 
            "title": "Modules"
        }, 
        {
            "location": "/Chapter04/#modules", 
            "text": "", 
            "title": "Modules"
        }, 
        {
            "location": "/Chapter04/#update-code-dir-to-use-your-current-workspace", 
            "text": "On puppet master  puppet\ncp -r /etc/puppetlabs/code /workspace/code      Update config in the server's config  file  /etc/puppetlabs/puppetserver/conf.d/puppetserver.conf  and update   master-code-dir: /etc/puppetlabs/code  to   master-code-dir: /workspace/code  (assuming you are using /workspace as your working/developement directory on the puppet master to store the code at )  Restart Puppet Server   shell\nservice puppetserver restart    This may take time.", 
            "title": "Update code dir to use your current workspace"
        }, 
        {
            "location": "/Chapter04/#generating-modules", 
            "text": "Change into the directory for production env   sh\ncd /workspace/code/environments/production/modules  Using puppet module command, generate the scaffolding for  java  and  tomcat  modules  bash\n\npuppet module generate --skip-interview user-java\n\npuppet module generate --skip-interview  gshah-tomcat", 
            "title": "Generating Modules"
        }, 
        {
            "location": "/Chapter04/#writing-classes", 
            "text": "file:  modules/java/manifests/init.pp  class java {\n\n  package { [ 'epel-release', 'java-1.7.0-openjdk'] : \n    ensure =  installed,\n  }\n\n}", 
            "title": "Writing classes"
        }, 
        {
            "location": "/Chapter04/#node-definitions-applying-the-code", 
            "text": "To apply the default class from java module, create a node definition   create file:  environments/production/manifests/app.pp  add the node definition   node 'node1' {\n\n   include java\n\n}  To apply, login to  node1  and run puppet agent   ssh devops@node1\n\nsudo su\n\npuppet agent -t", 
            "title": "Node Definitions - Applying the code"
        }, 
        {
            "location": "/Chapter04/#writing-the-class-to-install-tomcat", 
            "text": "file:  modules/tomcat/manifests/install.pp  class tomcat::install {\n\n    include java\n\n    package { [ 'tomcat', 'tomcat-webapps' ]:\n      ensure   =  installed, \n      require  =  Package['epel-release']\n    }\n\n}  Add  tomcat::install  to node definition for node1 which should now look like   node 'node1' {\n\n   include java\n   include tomcat::install\n\n}  Apply on node1 by running puppet agent   [on node1, as root]\n\npuppet agent -t", 
            "title": "Writing the class to install tomcat"
        }, 
        {
            "location": "/Chapter04/#nano-project", 
            "text": "Now that you have learnt how to write a manifest and apply, and have gone through the class naming conventions, you have been tasked to create  the following classe with the specifications as give below,     class :  tomcat::service \n      resource : service \n      name : tomcat \n      ensure : running \n      enable : true     service resource should have a dependency on install class    apply it to node1 by updating the node definition.  Validate by visiting the IP address of the server and port 8081.     Note : Tomcat may take up to 10mins to come up for the first time. This is discussed in details on this page https://wiki.apache.org/tomcat/HowTo/FasterStartUp at the Entropy Source section. We are going to apply that fix in the subsequenct sections.   Also bootstrap node2 ( configure it to talk to the master), create a node definition identical to node1, and apply. Validate that the tomcat service is started on port 8082.", 
            "title": "Nano Project"
        }, 
        {
            "location": "/Chapter04/#simplify-run-list", 
            "text": "file:  modules/tomcat/manifests/init.pp  class tomcat {\n\n  include tomcat::install\n  include tomcat::service \n\n}  And  production/manifests/app.pp  \nnode 'node1' {\n\n  include tomcat\n\n}\n\n\nnode 'node2' {\n\n   include tomcat\n\n}  Question  : Why are we not including java anymore?", 
            "title": "Simplify Run List"
        }, 
        {
            "location": "/Chapter04/#managing-files", 
            "text": "Create file    create directory to hold files : modules/tomcat/files  create a file modules/tomcat/files/tomcat.conf and add the content from https://gist.github.com/initcron/01f8554fba3305a1bceee9df5ff0aa24     Create a class tomcat::config to copy this file to destinition     tomcat::config class   class tomcat::config {\n\n  file { '/etc/tomcat/tomcat.conf':\n    source    =  'puppet:///modules/tomcat/tomcat.conf',\n    owner    =  'tomcat', \n    group    =  'tomcat', \n    mode     =  '0644',\n    notify   =  Service['tomcat'] \n  }\n\n}  Call it from tomcat class (init.pp)  class tomcat {\n\n  include tomcat::install\n  include tomcat::config\n  include tomcat::service \n}  Apply on Node1 and Node2", 
            "title": "Managing Files"
        }, 
        {
            "location": "/Chapter05/", 
            "text": "Parameters and Facts\n\n\nPlaying with Scopes\n\n\napp.pp\n\n\n\n\n$color = 'blue'\n$car   = 'maruti'\n\nnode 'node1' {\n\n  include tomcat\n\n}\n\n\nnode 'node2' {\n\n   $color = 'green'\n   include tomcat\n\n}\n\n\n\n\nCreate tomcat::scope class\n\n\nclass tomcat::scope {\n\n   notify{\nprint the scope\n:\n     message =\n \n\n\n       FAVOURITE COLOR :  ${color}\n       FAVOURITE CAR   :  ${car}\n\n    \n\n  }\n\n}\n\n\n\n\nAdd this class to init.pp\n\n\nclass tomcat {\n\n  include tomcat::scope\n  include tomcat::install\n  include tomcat::config\n  include tomcat::service\n}\n\n\n\n\nApply on both node1 and node2 and see the difference?  \n\n\nQuestion: Why does it print two different values?\n\n\nInheritance and story of params.pp\n\n\ncreate file: modules/tomcat/params.pp\n\n\nclass tomcat::params {\n\n  $color = 'white'\n  $car   = 'figo'\n\n}\n\n\n\n\n\n\nUpdate tomcat::scope definition to inherit tomcat::params. Lets also define $color in this child class.  \n\n\nclass tomcat::scope inherits tomcat::params{\n\n   $color = 'yellow'\n\n\n   notify{\nprint the scope\n:\n     message =\n \n\n\n       FAVOURITE COLOR :  ${color}\n       FAVOURITE CAR   :  ${car}\n\n    \n\n  }\n\n}\n\n\n\n\nParameterising Tomcat Configs\n\n\ntomcat::params\n\n\nclass tomcat::params {\n\n  $color = 'white'\n  $car   = 'figo'\n  $user  = 'tomcat'\n  $group = 'tomcat'\n  $config_path  = '/etc/tomcat/tomcat.conf'\n  $packages  = [ 'tomcat', 'tomcat-webapps' ]\n  $service_name = 'tomcat'\n  $service_state = running\n\n}\n\n\n\n\n\ntomcat (init.pp)\n\n\nclass tomcat inherits tomcat::params{\n\n  include tomcat::scope\n  include tomcat::install\n  include tomcat::config\n  include tomcat::service\n}\n\n\n\n\nclass tomcat::install\n\n\nclass tomcat::install inherits tomcat{\n\n    include java\n\n    package { $::tomcat::packages:\n      ensure   =\n installed,\n      require  =\n Package['epel-release']\n    }\n\n}\n\n\n\n\n\nclass tomcat::config\n\n\nclass tomcat::config inherits tomcat{\n\n  file { $::tomcat::config_path:\n    source    =\n 'puppet:///modules/tomcat/tomcat.conf',\n    owner    =\n $::tomcat::user,\n    group    =\n $::tomcat::group,\n    mode     =\n '0644',\n    notify   =\n Service['tomcat']\n  }\n\n}\n\n\n\n\n\nclass tomcat::service\n\n\nclass tomcat::service inherits tomcat{\n\n   service { $::tomcat::service_name:\n     ensure   =\n $::tomcat::service_state,\n     enable   =\n true,\n     require  =\n Class['tomcat::install'],\n   }\n}\n\n\n\n\n\nCreating base module\n\n\ncd /workspace/code/environments/production/modules\n\npuppet module generate --skip-interview user-base\n\nmv /workspace/base.pp base/manifests/init.pp\n\n\n\n\n\nAdd class to modules/base/manifests/init.pp. Code for this class can be availed from\nhttps://gist.github.com/initcron/dd302fe9fabcc9a1af071394bf8e8d6a\n\n\nAdd the base class to one of the nodes, and see if you could apply\n\n\ne.g. for \nnode2\n definition in app.pp\n\n\n\nnode 'node2' {\n\n   include base\n\n   $color = 'green'\n   include tomcat\n\n}\n\n\n\n\nQuestion\n :  What happens when you apply this class on node2 by running puppet agent ??\n\n\nLets use params.pp for doing platform specific configurations,\n\n\nclass base::params {\n\n  case $::os['family'] {\n    'Debian': {\n      $ntp_service = 'ntp'\n    }\n    'RedHat': {\n      $ntp_service = 'ntpd'\n    }\n  }\n\n\n}\n\n\n\n\nAnd to use these params, we need to\n  * inherit base::params in base class (init.pp)\n  * parameterize the service name\n\n\nUpdate init.pp with the above two changes. Here is the updated file for your reference https://gist.github.com/initcron/c8b6530dbae41c47c0d864d2a594844e\n\n\nUsing Facts\n\n\nLets also start using facts inside modules. To do this, lets create a file resource which generates /etc/motd and prints information about the system\n\n\nUpdate modules/base/manifests/init.pp and add the following resource.\n\n\n    file { '/etc/motd':\n      ensure   =\n file,\n      owner    =\n 'root',\n      content  =\n \n\n\n         This server is a property of XYZ Inc.\n\n         SYSTEM INFO\n         ============\n\n         Hostname     : ${::fqdn}\n         IP Address   : ${::ipaddress}\n         Memory       : ${::memory['system']['total']}\n         Cores        : ${::processors['count']}\n         OS           : ${::os['distro']['description']}\n\n\n      \n\n\n    }\n\n\n\n\nApply on all nodes and validate.", 
            "title": "Parameters and Facts"
        }, 
        {
            "location": "/Chapter05/#parameters-and-facts", 
            "text": "", 
            "title": "Parameters and Facts"
        }, 
        {
            "location": "/Chapter05/#playing-with-scopes", 
            "text": "app.pp  \n\n$color = 'blue'\n$car   = 'maruti'\n\nnode 'node1' {\n\n  include tomcat\n\n}\n\n\nnode 'node2' {\n\n   $color = 'green'\n   include tomcat\n\n}  Create tomcat::scope class  class tomcat::scope {\n\n   notify{ print the scope :\n     message =   \n\n       FAVOURITE COLOR :  ${color}\n       FAVOURITE CAR   :  ${car}\n\n     \n  }\n\n}  Add this class to init.pp  class tomcat {\n\n  include tomcat::scope\n  include tomcat::install\n  include tomcat::config\n  include tomcat::service\n}  Apply on both node1 and node2 and see the difference?    Question: Why does it print two different values?", 
            "title": "Playing with Scopes"
        }, 
        {
            "location": "/Chapter05/#inheritance-and-story-of-paramspp", 
            "text": "create file: modules/tomcat/params.pp  class tomcat::params {\n\n  $color = 'white'\n  $car   = 'figo'\n\n}  Update tomcat::scope definition to inherit tomcat::params. Lets also define $color in this child class.    class tomcat::scope inherits tomcat::params{\n\n   $color = 'yellow'\n\n\n   notify{ print the scope :\n     message =   \n\n       FAVOURITE COLOR :  ${color}\n       FAVOURITE CAR   :  ${car}\n\n     \n  }\n\n}", 
            "title": "Inheritance and story of params.pp"
        }, 
        {
            "location": "/Chapter05/#parameterising-tomcat-configs", 
            "text": "tomcat::params  class tomcat::params {\n\n  $color = 'white'\n  $car   = 'figo'\n  $user  = 'tomcat'\n  $group = 'tomcat'\n  $config_path  = '/etc/tomcat/tomcat.conf'\n  $packages  = [ 'tomcat', 'tomcat-webapps' ]\n  $service_name = 'tomcat'\n  $service_state = running\n\n}  tomcat (init.pp)  class tomcat inherits tomcat::params{\n\n  include tomcat::scope\n  include tomcat::install\n  include tomcat::config\n  include tomcat::service\n}  class tomcat::install  class tomcat::install inherits tomcat{\n\n    include java\n\n    package { $::tomcat::packages:\n      ensure   =  installed,\n      require  =  Package['epel-release']\n    }\n\n}  class tomcat::config  class tomcat::config inherits tomcat{\n\n  file { $::tomcat::config_path:\n    source    =  'puppet:///modules/tomcat/tomcat.conf',\n    owner    =  $::tomcat::user,\n    group    =  $::tomcat::group,\n    mode     =  '0644',\n    notify   =  Service['tomcat']\n  }\n\n}  class tomcat::service  class tomcat::service inherits tomcat{\n\n   service { $::tomcat::service_name:\n     ensure   =  $::tomcat::service_state,\n     enable   =  true,\n     require  =  Class['tomcat::install'],\n   }\n}", 
            "title": "Parameterising Tomcat Configs"
        }, 
        {
            "location": "/Chapter05/#creating-base-module", 
            "text": "cd /workspace/code/environments/production/modules\n\npuppet module generate --skip-interview user-base\n\nmv /workspace/base.pp base/manifests/init.pp  Add class to modules/base/manifests/init.pp. Code for this class can be availed from\nhttps://gist.github.com/initcron/dd302fe9fabcc9a1af071394bf8e8d6a  Add the base class to one of the nodes, and see if you could apply  e.g. for  node2  definition in app.pp  \nnode 'node2' {\n\n   include base\n\n   $color = 'green'\n   include tomcat\n\n}  Question  :  What happens when you apply this class on node2 by running puppet agent ??  Lets use params.pp for doing platform specific configurations,  class base::params {\n\n  case $::os['family'] {\n    'Debian': {\n      $ntp_service = 'ntp'\n    }\n    'RedHat': {\n      $ntp_service = 'ntpd'\n    }\n  }\n\n\n}  And to use these params, we need to\n  * inherit base::params in base class (init.pp)\n  * parameterize the service name  Update init.pp with the above two changes. Here is the updated file for your reference https://gist.github.com/initcron/c8b6530dbae41c47c0d864d2a594844e", 
            "title": "Creating base module"
        }, 
        {
            "location": "/Chapter05/#using-facts", 
            "text": "Lets also start using facts inside modules. To do this, lets create a file resource which generates /etc/motd and prints information about the system  Update modules/base/manifests/init.pp and add the following resource.      file { '/etc/motd':\n      ensure   =  file,\n      owner    =  'root',\n      content  =   \n\n         This server is a property of XYZ Inc.\n\n         SYSTEM INFO\n         ============\n\n         Hostname     : ${::fqdn}\n         IP Address   : ${::ipaddress}\n         Memory       : ${::memory['system']['total']}\n         Cores        : ${::processors['count']}\n         OS           : ${::os['distro']['description']}\n\n\n       \n\n    }  Apply on all nodes and validate.", 
            "title": "Using Facts"
        }, 
        {
            "location": "/Chapter06/", 
            "text": "Templates\n\n\nConverting tomcat.conf into a template\n\n\nWe always start with the original file (e.g. \nhttps://gist.github.com/initcron/01f8554fba3305a1bceee9df5ff0aa24\n)\n\n\nCreate file structure to store the templates\n\n\n\n\nCreate a director \nmodules/manifests/templates\n\n\nCreate a ERB file for tomcat.conf at  \nmodules/manifests/templates/tomcat.conf.erb\n\n\nCopy over the contents of the original tomcat.conf. You could use the link above as a sample content \n\n\n\n\nWhat could go wrong ?\n\n\n\n\nYou may have named \ntemplates\n directory as \ntemplate\n Note the singular vs plural. It should be plural, with \ns\n.\n\n\nThere is also a possibility that you have a typo in the name. \n\n\nYou may have created templates directory at a wrong path. It MUST be at \n...modules/tomcat/templates\n\n\n\n\nNow lets start converting the file into a template. How do we do that? \n  * Keep the property names intact.  e.g. JAVA_HOME or TOMCAT_USER\n  * Start replacing the values, with template variables. This is where ERB tags are handy. e.g. \n\n\nOriginal content such as this\n\n\nTOMCAT_USER=\ntomcat\n                                                                                                            \nSHUTDOWN_WAIT=\n30\n                                                             \n\n\n\n\nbecomes\n\n\nTOMCAT_USER=\n%= @user \n                                                                                                            \nSHUTDOWN_WAIT=\n%= @shutdown_wait \n\n\n\n\n\n\n\nThe template variables which start with @var need to be defined as well. Do that in \ntomcat::params\n. We already have user defined, lets define the shutdown_wait. What value do we define here?  Well params.pp contains the sane default. So whatever came with the package/configs, and was present in \ntomcat.conf\n by default is what we use.\ne.g. \n\n\n\n\n  $shutdown_wait = 30\n\n\n\n\n\nTIP\n : Its always useful to define the params first in params.pp before replacing the values in the template with ERB tags. That way, you would not have to go figure what were the default values, as once replaces, those values are gone. Its also easir to just copy over the params back as template variables.\n\n\nExercise\n\n\nUpdate the following properties in \ntomcat.conf\n in the template, and define the defaults in \nparams.pp\n\n\n\n\nTOMCAT_CFG_LOADED\n\n\nJAVA_HOME\n\n\nxms\n\n\nxmx\n\n\nmaxpermsize\n\n\nCATALINA_BASE\n\n\nJASPER_HOME\n\n\nCATALINA_TMPDIR\n\n\nSECURITY_MANAGER\n\n\nSHUTDOWN_VERBOSE\n\n\nCATALINA_PID\n\n\n\n\nReferences :\n\n\n\n\ntomcat.conf.erb   : https://gist.github.com/initcron/71e939a22e018dbc27dd4ae7deb3a55e\n\n\ntomcat::params    : https://gist.github.com/initcron/b08de87a1e835852ac00772252a71a97\n\n\n\n\nCalling templates from config class\n\n\nCreating templates and params does not have an effect on the system unless you start generating the configs using templates. Currently we are using a file resource to generate this file. Lets convert that to using a template. \n\n\nIn \ntomcat::config\n class, update property of the file resource from\n\n\nsource    =\n 'puppet:///modules/tomcat/tomcat.conf',\n\n\n\n\n\nto\n\n\ncontent  =\n template('tomcat/tomcat.conf.erb'),\n\n\n\n\n\nHere is the code after making that change for your reference  https://gist.github.com/initcron/87d99703590825716bed515f7e8bf64f", 
            "title": "Templates"
        }, 
        {
            "location": "/Chapter06/#templates", 
            "text": "", 
            "title": "Templates"
        }, 
        {
            "location": "/Chapter06/#converting-tomcatconf-into-a-template", 
            "text": "We always start with the original file (e.g.  https://gist.github.com/initcron/01f8554fba3305a1bceee9df5ff0aa24 )  Create file structure to store the templates   Create a director  modules/manifests/templates  Create a ERB file for tomcat.conf at   modules/manifests/templates/tomcat.conf.erb  Copy over the contents of the original tomcat.conf. You could use the link above as a sample content    What could go wrong ?   You may have named  templates  directory as  template  Note the singular vs plural. It should be plural, with  s .  There is also a possibility that you have a typo in the name.   You may have created templates directory at a wrong path. It MUST be at  ...modules/tomcat/templates   Now lets start converting the file into a template. How do we do that? \n  * Keep the property names intact.  e.g. JAVA_HOME or TOMCAT_USER\n  * Start replacing the values, with template variables. This is where ERB tags are handy. e.g.   Original content such as this  TOMCAT_USER= tomcat                                                                                                             \nSHUTDOWN_WAIT= 30                                                                becomes  TOMCAT_USER= %= @user                                                                                                              \nSHUTDOWN_WAIT= %= @shutdown_wait     The template variables which start with @var need to be defined as well. Do that in  tomcat::params . We already have user defined, lets define the shutdown_wait. What value do we define here?  Well params.pp contains the sane default. So whatever came with the package/configs, and was present in  tomcat.conf  by default is what we use.\ne.g.      $shutdown_wait = 30  TIP  : Its always useful to define the params first in params.pp before replacing the values in the template with ERB tags. That way, you would not have to go figure what were the default values, as once replaces, those values are gone. Its also easir to just copy over the params back as template variables.", 
            "title": "Converting tomcat.conf into a template"
        }, 
        {
            "location": "/Chapter06/#exercise", 
            "text": "Update the following properties in  tomcat.conf  in the template, and define the defaults in  params.pp   TOMCAT_CFG_LOADED  JAVA_HOME  xms  xmx  maxpermsize  CATALINA_BASE  JASPER_HOME  CATALINA_TMPDIR  SECURITY_MANAGER  SHUTDOWN_VERBOSE  CATALINA_PID", 
            "title": "Exercise"
        }, 
        {
            "location": "/Chapter06/#references", 
            "text": "tomcat.conf.erb   : https://gist.github.com/initcron/71e939a22e018dbc27dd4ae7deb3a55e  tomcat::params    : https://gist.github.com/initcron/b08de87a1e835852ac00772252a71a97", 
            "title": "References :"
        }, 
        {
            "location": "/Chapter06/#calling-templates-from-config-class", 
            "text": "Creating templates and params does not have an effect on the system unless you start generating the configs using templates. Currently we are using a file resource to generate this file. Lets convert that to using a template.   In  tomcat::config  class, update property of the file resource from  source    =  'puppet:///modules/tomcat/tomcat.conf',  to  content  =  template('tomcat/tomcat.conf.erb'),  Here is the code after making that change for your reference  https://gist.github.com/initcron/87d99703590825716bed515f7e8bf64f", 
            "title": "Calling templates from config class"
        }, 
        {
            "location": "/deploy_app/", 
            "text": "Deploy Sysfoo to Application Servers\n\n\nCreate a defined type to deploy a warfile\n\n\nfile: modules/tomcat/manifests/deploy.pp\n\n\ndefine tomcat::deploy(\n   $deploy_url,\n   $checksum_value,\n   $checksum    =  'md5',\n   $deploy_path =  $::tomcat::deploy_path\n) {\n\n   file { \n${deploy_path}/${name}.war\n :\n      source          =\n \n${deploy_url}\n,\n      owner           =\n $::tomcat::user,\n      group           =\n $::tomcat::group,\n      checksum_value  =\n \n${checksum_value}\n,\n      checksum        =\n \n${checksum}\n,\n      notify          =\n Exec['purge_context'],\n   }\n\n   exec { 'purge_context':\n     command       =\n \nrm -rf  ${deploy_path}/${name}\n,\n     path          =\n '/usr/bin:/usr/sbin:/bin',\n     refreshonly   =\n true,\n     notify        =\n Service['tomcat'],\n   }\n}\n\n\n\n\nDefine relevant params\n\n\nfile: modules/tomcat/manifests/params.pp\n\n\n  $deploy_path  = '/var/lib/tomcat/webapps'\n\n\n\n\nUse the defined type\n\n\nfile: code/environments/production/manifests/app.pp\n\n\n  tomcat::deploy { \nsysfoo\n:\n    deploy_url      =\n 'https://6-94848332-gh.circle-artifacts.com/0/tmp/circle-artifacts.3grfYBu/sysfoo.war',\n    checksum_value  =\n 'e1611c2f62b5c01e7f620a19a73446ea',\n    checksum        =\n 'md5'\n  }", 
            "title": "Deploying App"
        }, 
        {
            "location": "/deploy_app/#deploy-sysfoo-to-application-servers", 
            "text": "", 
            "title": "Deploy Sysfoo to Application Servers"
        }, 
        {
            "location": "/deploy_app/#create-a-defined-type-to-deploy-a-warfile", 
            "text": "file: modules/tomcat/manifests/deploy.pp  define tomcat::deploy(\n   $deploy_url,\n   $checksum_value,\n   $checksum    =  'md5',\n   $deploy_path =  $::tomcat::deploy_path\n) {\n\n   file {  ${deploy_path}/${name}.war  :\n      source          =   ${deploy_url} ,\n      owner           =  $::tomcat::user,\n      group           =  $::tomcat::group,\n      checksum_value  =   ${checksum_value} ,\n      checksum        =   ${checksum} ,\n      notify          =  Exec['purge_context'],\n   }\n\n   exec { 'purge_context':\n     command       =   rm -rf  ${deploy_path}/${name} ,\n     path          =  '/usr/bin:/usr/sbin:/bin',\n     refreshonly   =  true,\n     notify        =  Service['tomcat'],\n   }\n}", 
            "title": "Create a defined type to deploy a warfile"
        }, 
        {
            "location": "/deploy_app/#define-relevant-params", 
            "text": "file: modules/tomcat/manifests/params.pp    $deploy_path  = '/var/lib/tomcat/webapps'", 
            "title": "Define relevant params"
        }, 
        {
            "location": "/deploy_app/#use-the-defined-type", 
            "text": "file: code/environments/production/manifests/app.pp    tomcat::deploy {  sysfoo :\n    deploy_url      =  'https://6-94848332-gh.circle-artifacts.com/0/tmp/circle-artifacts.3grfYBu/sysfoo.war',\n    checksum_value  =  'e1611c2f62b5c01e7f620a19a73446ea',\n    checksum        =  'md5'\n  }", 
            "title": "Use the defined type"
        }, 
        {
            "location": "/rspec/", 
            "text": "Rspec\n\n\nSet the Path\n\n\nThe following path need to be set in order to use rake, rspec etc.\n\n\n\nexport PATH=$PATH:/opt/puppetlabs/puppet/bin/\n\necho \nexport PATH=$PATH:/opt/puppetlabs/puppet/bin/\n \n ~/.bashrc\n\nsource ~/.bashrc\n\n\n\n\nInstall Required Tools\n\n\ngem install --no-ri --no-rdoc  puppet-lint puppet-syntax puppetlabs_spec_helper\ncd modules/java\nrspec-puppet-init\ngem install bundler\nbundle install\n\n\n\n\nValidate\n\n\nrake help\nrspec --help\n\n\n\n\nSmoke testing rspec and rake on Java module\n\n\n\n\nObserve Rakefile in modules/java\n\n\nValidate and run rspec tests\n\n\n\n\nrake validate\n\nrake spec\n\nrake test\n\necho $?\n\n\n\n\nmetadata may need to be changed to\n\n\n{\n  \nname\n: \ngshah-java\n,\n  \nversion\n: \n0.1.0\n,\n  \nauthor\n: \ngshah\n,\n  \nsummary\n: \nthis module installs openjdk 7 on RedHat\n,\n  \nlicense\n: \nApache-2.0\n,\n  \nsource\n: \n,\n  \nproject_page\n: null,\n  \nissues_url\n: null,\n  \ndependencies\n: [\n    {\nname\n:\npuppetlabs-stdlib\n,\nversion_requirement\n:\n= 4.17.0\n}\n  ],\n  \ndata_provider\n: null\n}\n\n\n\n\n\n\nWriting first unit test spec for tomcat\n\n\nfile: modules/tomcat/.fixtures.yml\n\n\nfixtures:\n  symlinks:\n    tomcat: \n#{source_dir}\n\n    java: \n#{source_dir}/../java\n\n\n\n\n\n\nSmoke Test\n\n\nrake validate\n\n\n\n\n[fix issues if any until the above command is successful]\n\n\nCreate a simple unit test for class tomcat (init.pp)\n\n\nfile: modules/tomcat/specs/classes/init_spec.rb\n\n\nrequire 'spec_helper'\ndescribe 'tomcat' do\n  context 'with default values for all parameters' do\n    it { should contain_class('tomcat') }\n  end\n\n    it { should contain_class('tomcat::install') }\n    it { should contain_class('tomcat::config') }\n    it { should contain_class('tomcat::service') }\n\n\nend\n\n\n\n\nRun Tests\n\n\nrake spec\n\n\n\n\nCreating specs for tomcat::config\n\n\nfile: specs/classes/config_spec.rb\n\n\nrequire 'spec_helper'\ndescribe 'tomcat::config' do\n\n  it { should contain_class('tomcat::config') }\n  it { is_expected.to compile }\n  it { is_expected.to contain_file('/etc/tomcat/tomcat.conf').with({\n        :mode    =\n '0644',\n        :owner   =\n 'tomcat',\n        :group   =\n 'tomcat',\n      }).that_notifies('Service[tomcat]')\n\n\n\n  }\nend\n\n\n\n\n\nExercise\n\n\nScanario 1\n: Create a spec for service class which validates\n  * if tomcat::service is defined\n  * if it contains a service resource with\n    * ensure value as running\n    * enable set to true\n    * requires on Class['tomcat::install']\n\n\nScanario 2\n: Create a spec for \nbase\n class which validates\n  * if ::base class is defined\n  * if it contains a service resource for \nntp\n with\n    * ensure value as running\n    * enable set to true\n  * Given the osfamily\n    * as RedHat, service class should expect \nntpd\n is the service name\n    * as Debian, should expect \nntp\n as the service name\n\n\nReading List\n\n\n\n\n\n\nUnit Testing with Puppet\n    https://puppet.com/blog/unit-testing-rspec-puppet-for-beginners\n\n\n\n\n\n\nNext Generation of Puppet Module Testing\n    https://puppet.com/blog/next-generation-of-puppet-module-testing\n\n\n\n\n\n\nRspec Matchers for Puppet\n    http://rspec-puppet.com/matchers/\n\n\n\n\n\n\nPuppet-rspec Tutorial\n    http://rspec-puppet.com/tutorial/\n\n\n\n\n\n\nSample Unit Tests with Spec\n    https://github.com/desc/puppet-reprepro/blob/master/spec/classes/init_spec.rb\n\n\n\n\n\n\nhttp://terrarum.net/blog/puppet-testing-part-1.html\n\n\n\n\n\n\nhttps://wikimatze.de/getting-started-with-rspec-puppet/", 
            "title": "Rspec"
        }, 
        {
            "location": "/rspec/#rspec", 
            "text": "", 
            "title": "Rspec"
        }, 
        {
            "location": "/rspec/#set-the-path", 
            "text": "The following path need to be set in order to use rake, rspec etc.  \nexport PATH=$PATH:/opt/puppetlabs/puppet/bin/\n\necho  export PATH=$PATH:/opt/puppetlabs/puppet/bin/    ~/.bashrc\n\nsource ~/.bashrc", 
            "title": "Set the Path"
        }, 
        {
            "location": "/rspec/#install-required-tools", 
            "text": "gem install --no-ri --no-rdoc  puppet-lint puppet-syntax puppetlabs_spec_helper\ncd modules/java\nrspec-puppet-init\ngem install bundler\nbundle install  Validate  rake help\nrspec --help", 
            "title": "Install Required Tools"
        }, 
        {
            "location": "/rspec/#smoke-testing-rspec-and-rake-on-java-module", 
            "text": "Observe Rakefile in modules/java  Validate and run rspec tests   rake validate\n\nrake spec\n\nrake test\n\necho $?  metadata may need to be changed to  {\n   name :  gshah-java ,\n   version :  0.1.0 ,\n   author :  gshah ,\n   summary :  this module installs openjdk 7 on RedHat ,\n   license :  Apache-2.0 ,\n   source :  ,\n   project_page : null,\n   issues_url : null,\n   dependencies : [\n    { name : puppetlabs-stdlib , version_requirement : = 4.17.0 }\n  ],\n   data_provider : null\n}", 
            "title": "Smoke testing rspec and rake on Java module"
        }, 
        {
            "location": "/rspec/#writing-first-unit-test-spec-for-tomcat", 
            "text": "file: modules/tomcat/.fixtures.yml  fixtures:\n  symlinks:\n    tomcat:  #{source_dir} \n    java:  #{source_dir}/../java   Smoke Test  rake validate  [fix issues if any until the above command is successful]  Create a simple unit test for class tomcat (init.pp)  file: modules/tomcat/specs/classes/init_spec.rb  require 'spec_helper'\ndescribe 'tomcat' do\n  context 'with default values for all parameters' do\n    it { should contain_class('tomcat') }\n  end\n\n    it { should contain_class('tomcat::install') }\n    it { should contain_class('tomcat::config') }\n    it { should contain_class('tomcat::service') }\n\n\nend  Run Tests  rake spec", 
            "title": "Writing first unit test spec for tomcat"
        }, 
        {
            "location": "/rspec/#creating-specs-for-tomcatconfig", 
            "text": "file: specs/classes/config_spec.rb  require 'spec_helper'\ndescribe 'tomcat::config' do\n\n  it { should contain_class('tomcat::config') }\n  it { is_expected.to compile }\n  it { is_expected.to contain_file('/etc/tomcat/tomcat.conf').with({\n        :mode    =  '0644',\n        :owner   =  'tomcat',\n        :group   =  'tomcat',\n      }).that_notifies('Service[tomcat]')\n\n\n\n  }\nend", 
            "title": "Creating specs for tomcat::config"
        }, 
        {
            "location": "/rspec/#exercise", 
            "text": "Scanario 1 : Create a spec for service class which validates\n  * if tomcat::service is defined\n  * if it contains a service resource with\n    * ensure value as running\n    * enable set to true\n    * requires on Class['tomcat::install']  Scanario 2 : Create a spec for  base  class which validates\n  * if ::base class is defined\n  * if it contains a service resource for  ntp  with\n    * ensure value as running\n    * enable set to true\n  * Given the osfamily\n    * as RedHat, service class should expect  ntpd  is the service name\n    * as Debian, should expect  ntp  as the service name", 
            "title": "Exercise"
        }, 
        {
            "location": "/rspec/#reading-list", 
            "text": "Unit Testing with Puppet\n    https://puppet.com/blog/unit-testing-rspec-puppet-for-beginners    Next Generation of Puppet Module Testing\n    https://puppet.com/blog/next-generation-of-puppet-module-testing    Rspec Matchers for Puppet\n    http://rspec-puppet.com/matchers/    Puppet-rspec Tutorial\n    http://rspec-puppet.com/tutorial/    Sample Unit Tests with Spec\n    https://github.com/desc/puppet-reprepro/blob/master/spec/classes/init_spec.rb    http://terrarum.net/blog/puppet-testing-part-1.html    https://wikimatze.de/getting-started-with-rspec-puppet/", 
            "title": "Reading List"
        }
    ]
}